import requests
import subprocess
import sys

def check_ollama():
    print("üîç Diagnostic Ollama...")
    
    # V√©rifier si Ollama est install√©
    try:
        result = subprocess.run(["ollama", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ Ollama est install√©")
            print(f"   Version: {result.stdout.strip()}")
        else:
            print("‚ùå Ollama n'est pas install√© ou pas dans le PATH")
            return False
    except FileNotFoundError:
        print("‚ùå Ollama n'est pas install√©")
        return False
    
    # V√©rifier si le serveur tourne
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Serveur Ollama d√©marr√©")
            models = response.json().get("models", [])
            if models:
                print("üì¶ Mod√®les disponibles:")
                for model in models:
                    print(f"   - {model['name']}")
            else:
                print("‚ö†Ô∏è  Aucun mod√®le t√©l√©charg√©")
        else:
            print("‚ùå Serveur Ollama inaccessible")
            return False
    except requests.exceptions.ConnectionError:
        print("‚ùå Le serveur Ollama ne tourne pas")
        print("üí° D√©marrez-le avec: ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False
    
    return True

if __name__ == "__main__":
    check_ollama()